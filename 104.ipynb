{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c89d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b598ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! api_key is not default parameter.\n",
      "                api_key was transferred to model_kwargs.\n",
      "                Please confirm that api_key is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Anthropic' object has no attribute 'count_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m api_key, \u001b[33m\"\u001b[39m\u001b[33mSet ANTHROPIC_API_KEY in your environment!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Correct usage with api_key param\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m llm = \u001b[43mChatAnthropic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-sonnet-20240229\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mecho_node\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     14\u001b[39m     user_msg = state.get(\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHello!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:183\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    182\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/load/serializable.py:120\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._lc_kwargs = kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:345\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m values, fields_set, validation_error = \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:1106\u001b[39m, in \u001b[36mvalidate_model\u001b[39m\u001b[34m(model, input_data, cls)\u001b[39m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     values = \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1108\u001b[39m     errors.append(ErrorWrapper(exc, loc=ROOT_KEY))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_community/llms/anthropic.py:109\u001b[39m, in \u001b[36m_AnthropicCommon.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    107\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mHUMAN_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.HUMAN_PROMPT\n\u001b[32m    108\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mAI_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.AI_PROMPT\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mcount_tokens\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount_tokens\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import anthropic python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease it install it with `pip install anthropic`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Anthropic' object has no attribute 'count_tokens'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "\n",
    "# Make sure ANTHROPIC_API_KEY is set\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "assert api_key, \"Set ANTHROPIC_API_KEY in your environment!\"\n",
    "\n",
    "# Correct usage with api_key param\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", api_key=api_key)\n",
    "\n",
    "def echo_node(state: dict) -> dict:\n",
    "    user_msg = state.get(\"input\", \"Hello!\")\n",
    "    response = llm.invoke(user_msg)\n",
    "    return {\"input\": user_msg, \"output\": response.content}\n",
    "\n",
    "builder = StateGraph()\n",
    "builder.add_node(\"ClaudeEcho\", RunnableLambda(echo_node))\n",
    "builder.set_entry_point(\"ClaudeEcho\")\n",
    "builder.add_edge(\"ClaudeEcho\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"input\": \"Hello Claude! Just testing LangGraph integration.\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "881b1154",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Anthropic' object has no attribute 'count_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m api = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mANTHROPIC_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Define the LLM node\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m llm = \u001b[43mChatAnthropic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-sonnet-20240229\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manthropic_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mecho_node\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     11\u001b[39m     user_msg = state.get(\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHello!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:183\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    182\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/load/serializable.py:120\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._lc_kwargs = kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:345\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m values, fields_set, validation_error = \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:1106\u001b[39m, in \u001b[36mvalidate_model\u001b[39m\u001b[34m(model, input_data, cls)\u001b[39m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     values = \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1108\u001b[39m     errors.append(ErrorWrapper(exc, loc=ROOT_KEY))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_community/llms/anthropic.py:109\u001b[39m, in \u001b[36m_AnthropicCommon.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    107\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mHUMAN_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.HUMAN_PROMPT\n\u001b[32m    108\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mAI_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.AI_PROMPT\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mcount_tokens\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount_tokens\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import anthropic python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease it install it with `pip install anthropic`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Anthropic' object has no attribute 'count_tokens'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "import os\n",
    "api = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Define the LLM node\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", anthropic_api_key=api)\n",
    "\n",
    "def echo_node(state: dict) -> dict:\n",
    "    user_msg = state.get(\"input\", \"Hello!\")\n",
    "    response = llm.invoke(user_msg)\n",
    "    return {\"input\": user_msg, \"output\": response.content}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph()\n",
    "builder.add_node(\"ClaudeEcho\", RunnableLambda(echo_node))\n",
    "builder.set_entry_point(\"ClaudeEcho\")\n",
    "builder.add_edge(\"ClaudeEcho\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# Run it\n",
    "result = graph.invoke({\"input\": \"Hello Claude! Just testing LangGraph integration.\"})\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
