{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b0bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2cadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58.2\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "print(anthropic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c65c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatAnthropic` was deprecated in LangChain 0.0.28 and will be removed in 0.2. An updated version of the class exists in the langchain-anthropic package and should be used instead. To use it run `pip install -U langchain-anthropic` and import as `from langchain_anthropic import ChatAnthropic`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Anthropic' object has no attribute 'count_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatAnthropic\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm = \u001b[43mChatAnthropic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-sonnet-20240229\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(llm.invoke(\u001b[33m\"\u001b[39m\u001b[33mHello Claude!\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:183\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    182\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_core/load/serializable.py:120\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._lc_kwargs = kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:345\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m values, fields_set, validation_error = \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/pydantic/v1/main.py:1106\u001b[39m, in \u001b[36mvalidate_model\u001b[39m\u001b[34m(model, input_data, cls)\u001b[39m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     values = \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1108\u001b[39m     errors.append(ErrorWrapper(exc, loc=ROOT_KEY))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangChainGraph/chain/lib/python3.13/site-packages/langchain_community/llms/anthropic.py:109\u001b[39m, in \u001b[36m_AnthropicCommon.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    107\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mHUMAN_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.HUMAN_PROMPT\n\u001b[32m    108\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mAI_PROMPT\u001b[39m\u001b[33m\"\u001b[39m] = anthropic.AI_PROMPT\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     values[\u001b[33m\"\u001b[39m\u001b[33mcount_tokens\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount_tokens\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import anthropic python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease it install it with `pip install anthropic`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Anthropic' object has no attribute 'count_tokens'"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "print(llm.invoke(\"Hello Claude!\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1009f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 1: Get prereg info\n",
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"class_name\"],\n",
    "    template=\"What is the prereg for the class {class_name} at UChicago?\"\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1, output_key=\"prereg_info\")\n",
    "\n",
    "# Chain 2: Check if required for major\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"prereg_info\"],\n",
    "    template=\"Is this class required for any majors based on this prereg info: {prereg_info}?\"\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2, output_key=\"check\")\n",
    "\n",
    "# Combine chains\n",
    "chain = SequentialChain(\n",
    "    chains=[chain_1, chain_2],\n",
    "    input_variables=[\"class_name\"],\n",
    "    output_variables=[\"check\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = chain.run({\"class_name\": \"20300 analysis\"})\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
